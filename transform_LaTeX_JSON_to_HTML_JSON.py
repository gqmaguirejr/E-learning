#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# -*- mode: python; python-indent-offset: 4 -*-
#
# ./transform_LaTeX_JSON_to_HTML_JSON.py --json fordiva.json [--acronyms acronyms.tex]
#
# Purpose: Transform the LaTeX JSON file that has been produced by my LaTeX template and produced an HTML JSON file.
# The resulting file can be used with my other program (to create calendar entries, MODS file, and insert titles into LADOK).
#
# Outputs a a JSON file with HTML in a file with the name augmented by "-HTML"
#
# Example:
# ./transform_LaTeX_JSON_to_HTML_JSON.py --json fordiva.json [--acronyms acronyms.tex]
# 
# Based upon earlier cleanup_pseudo_JSON-from_LaTeX.py
#
# 2025-08-13 G. Q. Maguire Jr.

#
import re
import sys

import json
#import argparse
import optparse
import os			# to make OS calls, here to get time zone info
import pprint


def remove_latex_comments(s):
    """
    Removes single-line LaTeX comments (%), ignoring escaped percent signs (\\%).

    Args:
        s (str): The input string with LaTeX comments.

    Returns:
        str: The string with comments completely removed.
    """
    processed_lines = []
    for line in s.split('\n'):
        # Find the first unescaped '%' on the line
        match = re.search(r'(?<!\\)%', line)
        if match:
            # If a comment is found, keep only the part of the line before it
            start_pos = match.start()
            processed_lines.append(line[:start_pos])
        else:
            # If no comment is found, keep the entire line
            processed_lines.append(line)
            
    return '\n'.join(processed_lines)

def convert_latex_comments_to_html(s):
    """
    Finds and converts single-line LaTeX comments (%) into HTML comments (),
    while correctly ignoring escaped percent signs (\\%).
    """
    processed_lines = []
    
    for line in s.split('\n'):
        match = re.search(r'(?<!\\)%', line)
        
        if match:
            start_pos = match.start()
            before_comment = line[:start_pos]
            comment_text = line[start_pos+1:] # The text after the '%'
            
            # *** YOUR CORRECTED LINE ***
            # Reconstruct the line with HTML comment tags
            new_line = f"{before_comment}<!-- {comment_text} -->"
            processed_lines.append(new_line)
        else:
            # If no comment is found, keep the line as is
            processed_lines.append(line)
            
    return '\n'.join(processed_lines)



def old_replace_latex_symbol(s, symbol, insert_symbol):
    global Verbose_Flag
    cmd_offset=s.find(symbol)
    while (cmd_offset) > 0:
        s1=s[:cmd_offset]
        s2=s[cmd_offset+len(symbol):]
        s=s1+insert_symbol+s2
        cmd_offset=s.find(symbol, cmd_offset)
    return s

def replace_latex_symbol(s, symbol, insert_symbol):
    """
    Replaces a LaTeX symbol and consumes one optional trailing space.
    
    Args:
        s (str): The input string.
        symbol (str): The LaTeX command to replace (e.g., '\\textregistered').
        insert_symbol (str): The string to substitute.

    Returns:
        str: The modified string.
    """
    # 1. Escape the input symbol to treat it as a literal string in the regex.
    #    This is important in case the symbol contains special regex characters.
    escaped_symbol = re.escape(symbol)
    
    # 2. Create a pattern that matches the symbol followed by ONE optional space.
    #    ' ?' matches zero or one space character.
    pattern = escaped_symbol + r' ?'
    
    # 3. Use re.sub() to perform the replacement.
    return re.sub(pattern, insert_symbol, s)


# usage: replace_latex_command(s1, '\\textit{', '<i>', '</i>')
def old_replace_latex_command(s, command, insert_at_start, insert_at_end):
    """
    Replaces a simple LaTeX command with content in braces, allowing for
    optional whitespace between the command and its argument.
    """
    command_name = command.lstrip('\\')
    
    # *** THE CRITICAL FIX ***
    # The \s* pattern is added to match zero or more whitespace characters
    # (spaces, tabs, newlines) between the command and the opening brace.
    pattern = rf'\\{command_name}\s*{{(.*?)}}'
    
    replacement = rf'{insert_at_start}\1{insert_at_end}'
    
    return re.sub(pattern, replacement, s)

def replace_latex_command(s, command, insert_at_start, insert_at_end):
    """
    Replaces a simple LaTeX command with content in braces, allowing for
    optional whitespace and correctly handling trailing punctuation.
    """
    # 1. Use re.escape() to safely handle the backslash in the command name.
    #    This is the most robust way to build the pattern.
    escaped_command = re.escape(command)

    # 2. *** THE CRITICAL FIX ***
    #    The pattern now uses [^}]+ to capture one or more characters
    #    that are NOT a closing brace. This is more precise and avoids
    #    the "greedy" behavior that was eating a following period.
    pattern = escaped_command + r'\s*\{([^}]+)\}'
    
    # 3. The replacement uses \1 to backreference the captured content.
    replacement = rf'{insert_at_start}\1{insert_at_end}'
    
    # 4. Use re.sub() to perform the replacement.
    return re.sub(pattern, replacement, s)


def replace_latex_environment(s, environment, insert_at_start, insert_at_end):
    """
    Replaces a LaTeX environment with specified start and end tags.

    This function finds all occurrences of `\\begin{env} ... \\end{env}`
    and replaces them, keeping the inner content.

    Args:
        s (str): The input string to process.
        environment (str): The name of the environment (e.g., 'itemize').
        insert_at_start (str): The string to replace the \\begin{...} tag.
        insert_at_end (str): The string to replace the \\end{...} tag.

    Returns:
        str: The modified string.
    """
    # 1. Create the regex pattern.
    #    - \\begin\s*\{...\} matches the opening tag with optional whitespace.
    #    - (.*?) captures the content in between, non-greedily.
    #    - \\end\s*\{...\} matches the closing tag.
    #    - The re.DOTALL flag is crucial to allow '.' to match newline characters.
    pattern = rf'\\begin\s*{{{environment}}}(.*?)\\end\s*{{{environment}}}'
    
    # 2. Create the replacement string.
    #    '\\1' is a backreference to the captured content.
    replacement = rf'{insert_at_start}\1{insert_at_end}'
    
    # 3. Use re.sub() to find all matches and replace them.
    return re.sub(pattern, replacement, s, flags=re.DOTALL)

def replace_latex_break_command(s, command_name, replacement):
    """
    Replaces a LaTeX line break command and its optional argument.

    Args:
        s (str): The input string to process.
        command_name (str): The name of the break command (e.g., 'linebreak').
        replacement (str): The string to substitute for the command.

    Returns:
        str: The modified string.
    """
    # 1. Create the regex pattern.
    #    - \\{command_name} matches the command itself.
    #    - \s* matches any optional whitespace.
    #    - (?:\[\d\])? is a non-capturing group that optionally matches
    #      a single digit inside square brackets.
    pattern = rf'\\{command_name}\s*(?:\[\d\])?'
    
    # 2. Use re.sub() to find all matches and replace them.
    return re.sub(pattern, replacement, s)

def remove_empty_paragraphs(s):
    """
    Removes empty <p> tags that only contain whitespace.

    Args:
        s (str): The input string (e.g., HTML content).

    Returns:
        str: The string with empty paragraphs removed.
    """
    # The pattern looks for a <p> tag, followed by any number of
    # whitespace characters (\s*), and then a closing </p> tag.
    # The re.IGNORECASE flag makes the match case-insensitive (so it also finds <P>).
    pattern = r'<p>\s*</p>'
    
    # Replace all occurrences of the pattern with an empty string.
    return re.sub(pattern, '', s, flags=re.IGNORECASE)

def remove_empty_listitems(s):
    """
    Removes empty <p> tags that only contain whitespace.

    Args:
        s (str): The input string (e.g., HTML content).

    Returns:
        str: The string with empty paragraphs removed.
    """
    # The pattern looks for a <p> tag, followed by any number of
    # whitespace characters (\s*), and then a closing </p> tag.
    # The re.IGNORECASE flag makes the match case-insensitive (so it also finds <P>).
    pattern = r'<li>\s*</li>'
    
    # Replace all occurrences of the pattern with an empty string.
    return re.sub(pattern, '', s, flags=re.IGNORECASE)

string_replacements = {
    # Rates and Ratios
    '\\meter\\per\\second': 'm/s', # or ms<sup>-1</sup>
    'meters per minute': 'm/min',
    'degrees per second': 'deg/s',
    'Litres per minute': 'L/min',
    'Coulombs per minute': 'C/min',
    'Exabits/s': 'Ebit/s',
    'GBytes/s': 'GB/s',
    'Gigabits/s': 'Gbit/s',
    'Gigabits/second': 'Gbit/s',
    'Gbit/sec': 'Gbit/s',
    'Gbps': 'Gbit/s',
    'joule/bit': 'J/bit',
    'Mbit/s': 'Mbit/s',
    'Mbits/s': 'Mbit/s',
    'Mbits/sec': 'Mbit/s',
    'Mbps': 'Mbit/s',
    'bits/sec': 'bit/s',
    'bits/second': 'bit/s',
    'bps': 'bit/s',
    'bytes/sec': 'B/s',
    'calls/day': 'calls/day',
    'calls/year': 'calls/year',
    'h/year': 'h/year',
    'ms/frame': 'ms/frame',
    's/transaction': 's/transaction',
    'SEK/kWh': 'SEK/kWh',
    'NOK/kWh': 'NOK/kWh',
    'â‚¬/MWh': 'â‚¬/MWh',
    'watt/second': 'W/s',
    'Wh/km': 'Wh/km',

    # Units with Superscripts
    '\\meter\\squared': 'm<sup>2</sup>',
    '\\meter\\cubed': 'm<sup>3</sup>',
    'atoms/cm2': 'atoms/cm<sup>2</sup>',
    'cd/m2': 'cd/m<sup>2</sup>',
    'cm2': 'cm<sup>2</sup>',
    'cm-1': 'cm<sup>-1</sup>',
    'cm-2': 'cm<sup>-2</sup>',
    'cmâˆ’2': 'cm<sup>-2</sup>', # Using an en-dash
    'cm-3': 'cm<sup>-3</sup>',
    'm2': 'm<sup>2</sup>',
    'm3': 'm<sup>3</sup>',
    'Âµm2': 'Âµm<sup>2</sup>',

    # Special Cases and Normalization
    'CO2-eq./km': 'CO<sub>2</sub>-eq/km',
    'S.cm-1': 'S/cm',
    'KiloWatts': 'kW',
    'TeraWatthours': 'TWh',
    'Terawatt-hours': 'TWh',
    'centigrade': 'Â°C',
    'Ã…ngstrÃ¶m': 'Ã…',
    'angstroms': 'Ã…',
    'angstrom': 'Ã…',

    # Angles
    '\\degree': 'Â°',
    '\\arcminute': "'",
    '\\arcsecond': '"',
    '\\radian': 'rad',

    # Common Scientific Units
    '\\astronomicalunit': 'au',
    '\\atmosphere': 'atm',
    '\\bar': 'bar',
    '\\candela': 'cd',
    '\\dalton': 'Da',
    '\\electronvolt': 'eV',
    '\\hertz': 'Hz',
    '\\joule': 'J',
    '\\kelvin': 'K',
    '\\knot': 'kn',
    '\\mole': 'mol',
    '\\newton': 'N',
    '\\ohm': 'Î©',
    '\\pascal': 'Pa',
    '\\siemens': 'S',
    '\\tesla': 'T',
    '\\volt': 'V',
    '\\watt': 'W',

    # Textual and Phrase-based Units
    '\\percent': '%', # note that this has to done be before the following
    '\\per': '/', # Converts commands like \meter\per\second
    '\\square': '<sup>2</sup>', # For units like \square\meter
    '\\cubic': '<sup>3</sup>',  # For units like \cubic\meter
    
    # Specific Compound Units
    'kilo parsec': 'kpc',
    'megakronor': 'Mkr',
    'gigakronor': 'Gkr',
    'million â‚¬': 'Mâ‚¬',
    'million SEK': 'MSEK',
    'Giga tons': 'Gt',
    'Terawatt-hours': 'TWh',
    'Gigaflop/Joule': 'GFLOP/J',
    'Gigaflop/second': 'GFLOP/s',
    'kibibit per second': 'Kibit/s', # Normalizing names
    'megamessages per second': 'MMS/s'
}


def preprocess_units(s, replacements):
    """
    Performs a series of direct string replacements for complex units.
    """
    for latex_str, replacement_str in replacements.items():
        s = s.replace(latex_str, replacement_str)
    return s


def replace_latex_qty(s):
    """
    Replaces LaTeX \\qty{number}{unit} and \\qty{number} commands.

    Args:
        s (str): The input string containing LaTeX commands.

    Returns:
        str: The string with \\qty commands replaced.
    """
    
    unit_mapping = {
        # Base SI
        '\\meter': 'm',
        '\\second': 's',
        '\\gram': 'g',

        # Electrical and Magnetic
        '\\ohm': 'Î©',
        '\\siemens': 'S',
        '\\hertz': 'Hz',
        '\\ampere': 'A',
        '\\volt': 'V',
        '\\watt': 'W',
        '\\farad': 'F',
        '\\tesla': 'T',
        '\\oersted': 'Oe',

        # Temperature and Energy
        '\\degreeCelsius': 'â„ƒ',
        '\\degreeKelvin': 'K', # Note: 'degree' is often omitted for Kelvin
        '\\joule': 'J',
        '\\electronvolt': 'eV',

        # Other Physical Units
        '\\pascal': 'Pa',
        '\\newton': 'N',
        '\\gray': 'Gy',
        '\\dalton': 'Da',

        # Currencies and Other Symbols
        '\\percent': '%',
        '\\euro': 'â‚¬',
        '\\sek': 'kr', # For Swedish Krona
        '\\degree': 'Â°',
        '\\angstrom': 'Ã…'



        # Add other units here
    }

    # *** THE CRITICAL FIX ***
    # The second group for the unit is now optional.
    # (?:\s*\{([^}]+)\})?  <-- This part makes the second argument optional
    pattern = r'\\qty\s*\{([^}]+)\}(?:\s*\{([^}]+)\})?'

    def replacer(match):
        number = match.group(1)
        unit_command = match.group(2) # This will be None if the unit is not present
        
        # If a unit was provided, process it
        if unit_command:
            unit_symbol = unit_mapping.get(unit_command, unit_command)
            # Return with the narrow non-breaking space and the unit
            return f'{number}\u202F{unit_symbol}'
        else:
            # If no unit was provided, just return the number
            return number

    return re.sub(pattern, replacer, s)

def replace_ordinals_and_fix_spacing(s):
    """
    Replaces LaTeX ordinal commands and correctly handles spacing
    before punctuation.
    """
    # 1. Perform your initial replacements as before.
    replacements = {
        '\\first': '(i) ',
        '\\Second': '(ii) ', # Assuming this should be lowercase 'second'
        '\\third': '(iii) ',
        '\\fourth': '(iv) ',
        '\\fifth': '(v) ',
        '\\sixth': '(vi) ',
        '\\seventh': '(vii) ',
        '\\eighth': '(viii) '
    }
    
    for command, replacement in replacements.items():
        s = s.replace(command, replacement)
        
    # 2. *** THE CRITICAL FIX ***
    #    Use a regex to remove any space that is immediately followed by
    #    a punctuation character from the set [, . ? ! : ;].
    #    The (?=...) is a "positive lookahead".
    cleanup_pattern = r' (?=[,.?!:;])'
    s = re.sub(cleanup_pattern, '', s)
    
    return s

def replace_latex_abbreviations(s):
    """
    Replaces LaTeX abbreviations like \\etal and \\eg with HTML,
    correctly handling surrounding punctuation.
    """
    # 1. Define the abbreviations and their replacements.
    #    The replacement text should not include a final period,
    #    as the logic will add it contextually.
    abbreviations = {
        'eg': 'e.g',
        'Eg': 'E.g',
        'ie': 'i.e',
        'Ie': 'I.e',
        'etc': 'etc',
        'etal': 'et al'  # The non-breaking space (~) becomes a regular space
    }

    # 2. Iterate through each command to apply the specific replacement rules.
    for command, text in abbreviations.items():
        
        # Rule 1: Handle the command when it's followed by \cite.
        # Pattern: \command, optional space, followed by \cite (lookahead)
        # Replaces with: <i>text.</i>&thinsp;
        s = re.sub(rf'\\{command}\s*(?=\\cite)', f'<i>{text}.</i>&thinsp;', s)
        
        # Rule 2: Handle the command when it's followed by a period.
        # Pattern: \command, optional space, and a literal period.
        # Replaces with: <i>text</i>. (to avoid a double period)
        s = re.sub(rf'\\{command}\s*\.', f'<i>{text}</i>.', s)

        # Rule 3: Handle the command when followed by other punctuation.
        # Pattern: \command, optional space, followed by , ! ? or ) (lookahead)
        # Replaces with: <i>text.</i>
        s = re.sub(rf'\\{command}\s*(?=[,!?\)])', f'<i>{text}.</i>', s)
        
        # Rule 4: Handle the default case (e.g., followed by a word).
        # This is the last and most general rule. It will only apply to
        # commands that were not matched by the rules above.
        # Replaces with: <i>text.,</i> (with a comma and space, as in the macro)
        s = re.sub(rf'\\{command}', f'<i>{text}.,</i> ', s)
        
    return s

def replace_latex_accents(s):
    """
    Replaces LaTeX accent commands with their corresponding pre-composed
    Unicode characters using the unicodedata library. This version has a
    more comprehensive list of standard LaTeX accents.
    """
    
    # 1. A more comprehensive map of LaTeX accent commands to their
    #    Unicode COMBINING character codes.
    accent_map = {
        # Standard European accents
        '\\`': '\u0300',  # Combining Grave Accent
        "\\'": '\u0301',  # Combining Acute Accent
        "\\^": '\u0302',  # Combining Circumflex Accent
        "\\~": '\u0303',  # Combining Tilde
        '\\"': '\u0308',  # Combining Diaeresis (umlaut)
        "\\H": '\u030B',  # Combining Double Acute Accent
        
        # Dot, Ring, and Macron accents
        "\\.": '\u0307',  # Combining Dot Above
        "\\r": '\u030A',  # Combining Ring Above
        "\\=": '\u0304',  # Combining Macron
        "\\bar": '\u0305', # Combining Overline (often visually similar to macron)
        
        # Other common accents
        "\\v": '\u030C',  # Combining Caron (haÄek)
        "\\u": '\u0306',  # Combining Breve
        "\\h": '\u0309',  # Combining Hook Above
        "\\t": '\u0361',  # Combining Double Inverted Breve (tie)
        
        # Under-accents
        "\\c": '\u0327',  # Combining Cedilla
        "\\k": '\u0328',  # Combining Ogonek
        "\\d": '\u0323',  # Combining Dot Below
        "\\b": '\u0331',  # Combining Macron Below
        
    }

    # 2. Build a single regex pattern from the accent_map keys.
    #    This is more efficient than looping in Python.
    pattern = r'({0})\s*{{([^}}]*)}}'.format('|'.join(re.escape(k) for k in accent_map.keys()))

    def replacer(match):
        command = match.group(1)
        base_text = match.group(2)
        combining_char = accent_map.get(command)
        
        # Recursively process the inner text first to handle nested accents
        processed_base = replace_latex_accents(base_text)
        
        # Combine and normalize
        combined_sequence = processed_base + combining_char
        return unicodedata.normalize('NFC', combined_sequence)

    # Loop until no more replacements can be made to handle nesting
    while re.search(pattern, s):
        s = re.sub(pattern, replacer, s)
        
    return s


latex_to_html_entities = {
    '\\ldots': '&mldr;',
    '\\textregistered': '&reg;',
    '\\texttrademark': '&trade;',
    '\\textcopyright': '&copy;',
    '\\S': '&sect;',  # Section symbol
    '\\P': '&para;',   # Paragraph symbol (pilcrow)
    '\\textcircledP': '&copysr;', # Sound Recording Copyright - U+2117

    '\\textservicemark': 'â„ ',
    '\\textcopyleft': '\u1f12f',


}


def replace_latex_symbols_from_dict(s, replacement_dict):
    """
    Iterates through a dictionary of LaTeX commands and their HTML
    replacements, applying them to a string.

    Args:
        s (str): The input string.
        replacement_dict (dict): A dictionary where keys are LaTeX commands
                                 (e.g., '\\textregistered') and values are
                                 their HTML replacements (e.g., '&reg;').

    Returns:
        str: The modified string.
    """
    # Iterate through each item in the dictionary
    for command, replacement in replacement_dict.items():
        # Escape the command to make it safe for use in a regex
        escaped_command = re.escape(command)
        
        # This pattern finds the command and one optional trailing space
        pattern = escaped_command + r' ?'
        
        # Perform the substitution
        s = re.sub(pattern, replacement, s)
        
    return s

def perform_substitutions(s):

    #s=s.replace('\x0c', '')  # Unsure if this is necessary

    s=s.replace('\u2029', '</p><p>')
    s=s.replace('\u2028', '<BR>')
    s=s.replace('\\\\', '\\')

    s=s.replace('\&', '&amp;')
    s=s.replace('\\hbox{-}', '\u2011')	# NON-BREAKING HYPHEN
    s=s.replace('\\,', '\u202f')     	# NARROW NO-BREAK SPACE
    s=s.replace('\\prime,', '\u2032')   # Prime

    s=replace_latex_break_command(s, 'linebreak', '<BR>')

    s=replace_latex_command(s, '\\textit', '<i>', '</i>')
    s=replace_latex_command(s, '\\textbf', '<strong>', '</strong>')
    s=replace_latex_command(s, '\\texttt', '<tt>', '</tt>')
    s=replace_latex_command(s, '\\textsubscript', '<sub>', '</sub>')
    s=replace_latex_command(s, '\\textsuperscript', '<sup>', '</sup>')
    s=replace_latex_command(s, '\\mbox', '<span>', '</span>')
    s=replace_latex_command(s, '\\engExpl', '<!-- ', ' -->')
    s=replace_latex_command(s, '\\tothe', '<sup>', '</sup>')
    s=replace_latex_environment(s, 'itemize', '</p><p><ul>', '</li></ul></p><p>')
    s=replace_latex_environment(s, 'enumerate', '</p><p><ol>', '</li></ol></p><p>')
    
    s=s.replace('\\item', '<li>')
    s=s.replace('<li> ', '<li>')
    s=s.replace(' <li>', '<li>')
    s=s.replace(' <li>', '<li>')


    s=s.replace('<BR></p>', '</p>')
    s=s.replace('<BR></li>', '</li>')
    s=s.replace('<BR><li>', '</li><li>')

    s=s.replace('\\par', '</p><p>')

    s=s.replace('\n', ' ')

    # handle defines.tex macros
    s=replace_latex_abbreviations(s)

    s=replace_ordinals_and_fix_spacing(s)

    # convert these to the more general qty{}{} form
    s=s.replace('\\num', '\\qty')
    s=s.replace('\\SI', '\\qty')

    # replace more complex units before the replace_latex_qty() call
    s=preprocess_units(s, string_replacements)

    # handle \qty{}{} with some units
    s=replace_latex_qty(s)

    s=replace_latex_symbols_from_dict(s, latex_to_html_entities)

    # some final cleanup

    s=remove_empty_listitems(s)
    s=remove_empty_paragraphs(s)
    s=s.replace(' </p>', '</p>')
    s=s.replace('\\\\', '\\')
    s=s.replace('\\textbackslash ', '\\')
    return s

def process_latex_in_blocks(s):
    """
    Safely processes a LaTeX string by separating text and math blocks.
    This version correctly identifies blocks by content, not by index.
    """
    # 1. First, remove all comments from the entire string.
    s = remove_latex_comments(s)

    # 2. Define a regex pattern to find and CAPTURE all math environments.
    pattern = r'(\$.*?\S\$|\\\(.*?\\\)|\\\[.*?\\\])'
    
    # 3. Split the string by this pattern.
    blocks = re.split(pattern, s)
    
    # 4. Process the blocks.
    processed_blocks = []
    for block in blocks:
        if not block: # Skip any empty strings that result from the split
            continue
            
        # *** THE CRITICAL FIX ***
        # Check if the block is a math block by looking at its first characters.
        if block.startswith('$') or block.startswith('\\(') or block.startswith('\\['):
            print(f"mathblock: {block}")
            # This is a math block, so we append it unchanged.
            processed_blocks.append(block)
        else:
            # This is a text block, so we can safely process it.
            print(f"textblock: {block}")
            processed_block = replace_latex_accents(block)
            # Add any other text-only replacements here.
            processed_block=perform_substitutions(processed_block)

            processed_blocks.append(processed_block)
            
    # 5. Reconstitute the final string.
    return "".join(processed_blocks)

def replace_math_alphabets(s):
    """
    Replaces LaTeX math alphabet commands like \\mathbb{C} with their
    corresponding Unicode characters.
    """
    
    # 1. Define mapping tables for each math alphabet command.
    #    These can be expanded as needed.
    mathbb_map = {
        'A': 'ğ”¸', 'B': 'ğ”¹', 'C': 'â„‚', 'D': 'ğ”»', 'E': 'ğ”¼', 'F': 'ğ”½',
        'G': 'ğ”¾', 'H': 'â„', 'I': 'ğ•€', 'J': 'ğ•', 'K': 'ğ•‚', 'L': 'ğ•ƒ', 'M': 'ğ•„',
        'N': 'â„•', 'O': 'ğ•†', 'P': 'â„™',
        'Q': 'â„š', 'R': 'â„', 'S': 'ğ•Š', 'T': 'ğ•‹',
        'U': 'ğ•Œ', 'V': 'ğ•', 'W': 'ğ•', 'X': 'ğ•', 'Y': 'ğ•', 'Z': 'â„¤',

        # lower case
        'a': 'ğ•’', 'b': 'ğ•“', 'c': 'ğ•”', 'd': 'ğ••', 'e': 'ğ•–',
        'f': 'ğ•—', 'g': 'ğ•˜', 'h': 'ğ•™', 'i': 'ğ•š', 'ğ•›': 'ğ•›',
        'k': 'ğ•œ', 'l': 'ğ•', 'm': 'ğ•', 'n': 'ğ•Ÿ', 'o': 'ğ• ',
        'p': 'ğ•¡', 'q': 'ğ•¢', 'r': 'ğ•£', 's': 'ğ•¤', 't': 'ğ•¥',
        'u': 'ğ•¦', 'v': 'ğ•§', 'w': 'ğ•¨', 'x': 'ğ•©', 'y': 'ğ•ª', 'z': 'ğ•«',

        # digits
        '0': 'ğŸ˜', '1': 'ğŸ™', '2': 'ğŸš', '3': 'ğŸ›', '4': 'ğŸœ',
        '5': 'ğŸ', '6': 'ğŸ', '7': 'ğŸŸ', '8': 'ğŸ ', '9': 'ğŸ¡',

        # Greek
        'Î“': 'â„¾', 'Î ': 'â„¿', 'Î£': 'â…€',
        'Ï€': 'â„¼', 'Î³': 'â„½', 
        
    }

    # BB with italics
    mathbbit_map = {
        'D': 'â……', 'd': 'â…†', 'e': 'â…‡', 'i': 'â…ˆ', 'j': 'â…‰',
    }

    # VS2_roundhand = '\uFE01' # For \mathcal
    # upright, calligraphic style - roundhand
    mathcal_map = {
        'A': '\u1D49C\uFE01', 'B': '\u212C\uFE01', 'C': '\u1D49E\uFE01', 'D': '\u1D49F\uFE01', 
        'E': '\u2130\uFE01', 'F': '\u2131\uFE01', 'G': '\u1D4A2\uFE01', 'H': '\u210B\uFE01', 
        'I': '\u2110\uFE01', 'J': '\u1D4A5\uFE01', 'K': '\u1D4A6\uFE01', 'L': '\u2112\uFE01', 
        'M': '\u2133\uFE01', 'N': '\u1D4A9\uFE01', 'O': '\u1D4AA\uFE01', 'P': '\u1D4AB\uFE01', 
        'Q': '\u1D4AC\uFE01', 'R': '\u211B\uFE01', 'S': '\u1D4AE\uFE01', 'T': '\u1D4AF\uFE01', 
        'U': '\u1D4B0\uFE01', 'V': '\u1D4B1\uFE01', 'W': '\u1D4B2\uFE01', 'X': '\u1D4B3\uFE01', 
        'Y': '\u1D4B4\uFE01', 'Z': '\u1D4B5\uFE01',
        'a': '\u1D4B6\uFE01', 'b': '\u1D4B7\uFE01', 'c': '\u1D4B8\uFE01', 'd': '\u1D4B9\uFE01',
        'e': '\u212F\uFE01',  'f': '\u1D4BB\uFE01', 'g': '\u210A\uFE01',  'h': '\u1D4BD\uFE01',
        'i': '\u1D4BE\uFE01', 'j': '\u1D4BF\uFE01', 'k': '\u1D4C0\uFE01', 'l': '\u1D4C1\uFE01',
        'm': '\u1D4C\uFE01', 'n': '\u1D4C3\uFE01',  'o': '\u2134\uFE01',  'p': '\u1D4C5\uFE01',
        'q': '\u1D4C6\uFE01', 'r': '\u1D4C7\uFE01', 's': '\u1D4C8\uFE01', 't': '\u1D4C9\uFE01',
        'u': '\u1D4CA\uFE01', 'v': '\u1D4CB\uFE01', 'w': '\u1D4CC\uFE01', 'x': '\u1D4CD\uFE01',
        'y': '\u1D4CE\uFE01', 'z': '\u1D4CF\uFE01',
    }

        # upright, calligraphic style - roundhand
    mathcalbold_map = {
        'A': '\u1D4D0\uFE01', 'B': '\u1D4D1\uFE01', 'C': '\u1D4D2\uFE01', 'D': '\u1D4D3\uFE01', 
        'E': '\u1D4D4\uFE01', 'F': '\u1D4D5\uFE01', 'G': '\u1D4D6\uFE01', 'H': '\u1D4D7\uFE01', 
        'I': '\u1D4D8\uFE01', 'J': '\u1D4D9\uFE01', 'K': '\u1D4DA\uFE01', 'L': '\u1D4DB\uFE01', 
        'M': '\u1D4DC\uFE01', 'N': '\u1D4DD\uFE01', 'O': '\u1D4DE\uFE01', 'P': '\u1D4DF\uFE01', 
        'Q': '\u1D4E0\uFE01', 'R': '\u1D4E1\uFE01', 'S': '\u1D4E2\uFE01', 'T': '\u1D4E3\uFE01', 
        'U': '\u1D4E4\uFE01', 'V': '\u1D4E5\uFE01', 'W': '\u1D4E6\uFE01', 'X': '\u1D4E7\uFE01', 
        'Y': '\u1D4E8\uFE01', 'Z': '\u1D4E9\uFE01',
        'a': '\u1D4EA\uFE01', 'b': '\u1D4EB\uFE01', 'c': '\u1D4EC\uFE01', 'd': '\u1D4ED\uFE01',
        'e': '\u1D4EE\uFE01', 'f': '\u1D4EF\uFE01', 'g': '\u1D4F0\uFE01', 'h': '\u1D4F1\uFE01',
        'i': '\u1D4F2\uFE01', 'j': '\u1D4F3\uFE01', 'k': '\u1D4F4\uFE01', 'l': '\u1D4F5\uFE01',
        'm': '\u1D4F6\uFE01', 'm': '\u1D4F7\uFE01', 'o': '\u1D4F8\uFE01', 'p': '\u1D4F9\uFE01',
        'q': '\u1D4FA\uFE01', 'r': '\u1D4FB\uFE01', 's': '\u1D4FC\uFE01', 't': '\u1D4FD\uFE01',
        'u': '\u1D4FE\uFE01', 'v': '\u1D4FF\uFE01', 'w': '\u1D500\uFE01', 'x': '\u1D501\uFE01',
        'y': '\u1D502\uFE01', 'z': '\u1D503\uFE01',
    }

    
    # VS1_chancery = '\uFE00'  # For \mathscr
    # the more slanted, chancery or "script" style
    mathscr_map = {
        'A': '\u1D49C\uFE00', 'B': '\u212C\uFE00', 'C': '\u1D49E\uFE00', 'D': '\u1D49F\uFE00', 
        'E': '\u2130\uFE00', 'F': '\u2131\uFE00', 'G': '\u1D4A2\uFE00', 'H': '\u210B\uFE00', 
        'I': '\u2110\uFE00', 'J': '\u1D4A5\uFE00', 'K': '\u1D4A6\uFE00', 'L': '\u2112\uFE00', 
        'M': '\u2133\uFE00', 'N': '\u1D4A9\uFE00', 'O': '\u1D4AA\uFE00', 'P': '\u1D4AB\uFE00', 
        'Q': '\u1D4AC\uFE00', 'R': '\u211B\uFE00', 'S': '\u1D4AE\uFE00', 'T': '\u1D4AF\uFE00', 
        'U': '\u1D4B0\uFE00', 'V': '\u1D4B1\uFE00', 'W': '\u1D4B2\uFE00', 'X': '\u1D4B3\uFE00', 
        'Y': '\u1D4B4\uFE00', 'Z': '\u1D4B5\uFE00',
        'a': '\u1D4B6\uFE00', 'b': '\u1D4B7\uFE00', 'c': '\u1D4B8\uFE00', 'd': '\u1D4B9\uFE00',
        'e': '\u212F\uFE00',  'f': '\u1D4BB\uFE00', 'g': '\u210A\uFE00',  'h': '\u1D4BD\uFE00',
        'i': '\u1D4BE\uFE00', 'j': '\u1D4BF\uFE00', 'k': '\u1D4C0\uFE00', 'l': '\u1D4C1\uFE00',
        'm': '\u1D4C\uFE00',  'n': '\u1D4C3\uFE00', 'o': '\u2134\uFE00',  'p': '\u1D4C5\uFE00',
        'q': '\u1D4C6\uFE00', 'r': '\u1D4C7\uFE00', 's': '\u1D4C8\uFE00', 't': '\u1D4C9\uFE00',
        'u': '\u1D4CA\uFE00', 'v': '\u1D4CB\uFE00', 'w': '\u1D4CC\uFE00', 'x': '\u1D4CD\uFE00',
        'y': '\u1D4CE\uFE00', 'z': '\u1D4CF\uFE00',

    }

    mathscrbold_map = {
        'A': '\u1D4D0\uFE00', 'B': '\u1D4D1\uFE00', 'C': '\u1D4D2\uFE00', 'D': '\u1D4D3\uFE00', 
        'E': '\u1D4D4\uFE00', 'F': '\u1D4D5\uFE00', 'G': '\u1D4D6\uFE00', 'H': '\u1D4D7\uFE00', 
        'I': '\u1D4D8\uFE00', 'J': '\u1D4D9\uFE00', 'K': '\u1D4DA\uFE00', 'L': '\u1D4DB\uFE00', 
        'M': '\u1D4DC\uFE00', 'N': '\u1D4DD\uFE00', 'O': '\u1D4DE\uFE00', 'P': '\u1D4DF\uFE00', 
        'Q': '\u1D4E0\uFE00', 'R': '\u1D4E1\uFE00', 'S': '\u1D4E2\uFE00', 'T': '\u1D4E3\uFE00', 
        'U': '\u1D4E4\uFE00', 'V': '\u1D4E5\uFE00', 'W': '\u1D4E6\uFE00', 'X': '\u1D4E7\uFE00', 
        'Y': '\u1D4E8\uFE00', 'Z': '\u1D4E9\uFE00',
        'a': '\u1D4EA\uFE00', 'b': '\u1D4EB\uFE00', 'c': '\u1D4EC\uFE00', 'd': '\u1D4ED\uFE00',
        'e': '\u1D4EE\uFE00', 'f': '\u1D4EF\uFE00', 'g': '\u1D4F0\uFE00', 'h': '\u1D4F1\uFE00',
        'i': '\u1D4F2\uFE00', 'j': '\u1D4F3\uFE00', 'k': '\u1D4F4\uFE00', 'l': '\u1D4F5\uFE00',
        'm': '\u1D4F6\uFE00', 'm': '\u1D4F7\uFE00', 'o': '\u1D4F8\uFE00', 'p': '\u1D4F9\uFE00',
        'q': '\u1D4FA\uFE00', 'r': '\u1D4FB\uFE00', 's': '\u1D4FC\uFE00', 't': '\u1D4FD\uFE00',
        'u': '\u1D4FE\uFE00', 'v': '\u1D4FF\uFE00', 'w': '\u1D500\uFE00', 'x': '\u1D501\uFE00',
        'y': '\u1D502\uFE00', 'z': '\u1D503\uFE00',
    }


    mathfrak_map = {
        # upper case

        'A': 'ğ”„', 'B': 'ğ”…', 'C': 'â„­', 'D': 'ğ”‡', 'E': 'ğ”ˆ',
        'F': 'ğ”‰', 'G': 'ğ”Š', 'H': 'â„Œ', 'I': 'â„‘', 'J': 'ğ”',
        'K': 'ğ”', 'L': 'ğ”', 'M': 'ğ”', 'N': 'ğ”‘', 'O': 'ğ”’',
        'P': 'ğ”“', 'Q': 'ğ””', 'R': 'â„œ', 'S': 'ğ”–', 'T': 'ğ”—',
        'U': 'ğ”˜', 'V': 'ğ”™', 'W': 'ğ”š', 'X': 'ğ”›', 'Y': 'ğ”œ', 'Z': 'â„¨',

        # lower case
        'a': 'ğ”', 'b': 'ğ”Ÿ', 'c': 'ğ” ', 'd': 'ğ”¡', 'e': 'ğ”¢',
        'f': 'ğ”£', 'g': 'ğ”¤', 'h': 'ğ”¥', 'i': 'ğ”¦', 'j': 'ğ”§',
        'k': 'ğ”¨', 'l': 'ğ”©', 'm': 'ğ”ª', 'n': 'ğ”«', 'o': 'ğ”¬',
        'p': 'ğ”­', 'q': 'ğ”®', 'r': 'ğ”¯', 's': 'ğ”°', 't': 'ğ”±',
        'u': 'ğ”²', 'v': 'ğ”³', 'w': 'ğ”´', 'x': 'ğ”µ', 'y': 'ğ”¶', 'z': 'ğ”·',

        # digits
    }

    mbfrak_map = {
        # upper case

        'A': 'ğ•¬', 'B': 'ğ•­', 'C': 'ğ•®', 'D': 'ğ•¯', 'E': 'ğ•°',
        'F': 'ğ•±', 'G': 'ğ•²', 'H': 'ğ•³', 'I': 'ğ•´', 'J': 'ğ•µ',
        'K': 'ğ•¶', 'L': 'ğ•·', 'M': 'ğ•¸', 'N': 'ğ•¹', 'O': 'ğ•º',
        'P': 'ğ•»', 'Q': 'ğ•¼', 'R': 'ğ•½', 'S': 'ğ•¾', 'T': 'ğ•¿',
        'U': 'ğ–€', 'V': 'ğ–', 'W': 'ğ–‚', 'X': 'ğ–ƒ', 'Y': 'ğ–„', 'Z': 'ğ–…',

        # lower case
        'a': 'ğ–†', 'b': 'ğ–‡', 'c': 'ğ–ˆ', 'd': 'ğ–‰', 'e': 'ğ–Š',
        'f': 'ğ–‹', 'g': 'ğ–Œ', 'h': 'ğ–', 'i': 'ğ–', 'j': 'ğ–',
        'k': 'ğ–', 'l': 'ğ–‘', 'm': 'ğ–’', 'n': 'ğ–“', 'o': 'ğ–”',
        'p': 'ğ–•', 'q': 'ğ––', 'r': 'ğ–—', 's': 'ğ–˜', 't': 'ğ–™',
        'u': 'ğ–š', 'v': 'ğ–›', 'w': 'ğ–œ', 'x': 'ğ–', 'y': 'ğ–', 'z': 'ğ–Ÿ',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ', '1': 'ğŸ', '2': 'ğŸ', '3': 'ğŸ‘', '4': 'ğŸ’',
        '5': 'ğŸ“', '6': 'ğŸ”', '7': 'ğŸ•', '8': 'ğŸ–', '9': 'ğŸ—',

    }

    # sans serif
    mathsf_map = {
        # upper case

        'A': 'ğ– ', 'B': 'ğ–¡', 'C': 'ğ–¢', 'D': 'ğ–£', 'E': 'ğ–¤',
        'F': 'ğ–¥', 'G': 'ğ–¦', 'H': 'ğ–§', 'I': 'ğ–¨', 'J': 'ğ–©',
        'K': 'ğ–ª', 'L': 'ğ–«', 'M': 'ğ–¬', 'N': 'ğ–­', 'O': 'ğ–®',
        'P': 'ğ–¯', 'Q': 'ğ–°', 'R': 'ğ–±', 'S': 'ğ–²', 'T': 'ğ–³',
        'U': 'ğ–´', 'V': 'ğ–µ', 'W': 'ğ–¶', 'X': 'ğ–·', 'Y': 'ğ–¸', 'Z': 'ğ–¹',

        # lower case
        'a': 'ğ–º', 'b': 'ğ–»', 'c': 'ğ–¼', 'd': 'ğ–½', 'e': 'ğ–¾',
        'f': 'ğ–¿', 'g': 'ğ—€', 'h': 'ğ—', 'i': 'ğ—‚', 'j': 'ğ—ƒ',
        'k': 'ğ—„', 'l': 'ğ—…', 'm': 'ğ—†', 'n': 'ğ—‡', 'o': 'ğ—ˆ',
        'p': 'ğ—‰', 'q': 'ğ—Š', 'r': 'ğ—‹', 's': 'ğ—Œ', 't': 'ğ—',
        'u': 'ğ—', 'v': 'ğ—', 'w': 'ğ—', 'x': 'ğ—‘', 'y': 'ğ—’', 'z': 'ğ—“',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ¢', '1': 'ğŸ£', '2': 'ğŸ¤', '3': 'ğŸ¥', '4': 'ğŸ¦',
        '5': 'ğŸ§', '6': 'ğŸ¨', '7': 'ğŸ©', '8': 'ğŸª', '9': 'ğŸ«',

    }

    mathsfit_map = {
        # upper case

        'A': 'ğ˜ˆ', 'B': 'ğ˜‰', 'C': 'ğ˜Š', 'D': 'ğ˜‹', 'E': 'ğ˜Œ',
        'F': 'ğ˜', 'G': 'ğ˜', 'H': 'ğ˜', 'I': 'ğ˜', 'J': 'ğ˜‘',
        'K': 'ğ˜’', 'L': 'ğ˜“', 'M': 'ğ˜”', 'N': 'ğ˜•', 'O': 'ğ˜–',
        'P': 'ğ˜—', 'Q': 'ğ˜˜', 'R': 'ğ˜™', 'S': 'ğ˜š', 'T': 'ğ˜›',
        'U': 'ğ˜œ', 'V': 'ğ˜', 'W': 'ğ˜', 'X': 'ğ˜Ÿ', 'Y': 'ğ˜ ', 'Z': 'ğ˜¡',

        # lower case
        'a': 'ğ˜¢', 'b': 'ğ˜£', 'c': 'ğ˜¤', 'd': 'ğ˜¥', 'e': 'ğ˜¦',
        'f': 'ğ˜§', 'g': 'ğ˜¨', 'h': 'ğ˜©', 'i': 'ğ˜ª', 'j': 'ğ˜«',
        'k': 'ğ˜¬', 'l': 'ğ˜­', 'm': 'ğ˜®', 'n': 'ğ˜¯', 'o': 'ğ˜°',
        'p': 'ğ˜±', 'q': 'ğ˜²', 'r': 'ğ˜³', 's': 'ğ˜´', 't': 'ğ˜µ',
        'u': 'ğ˜¶', 'v': 'ğ˜·', 'w': 'ğ˜¸', 'x': 'ğ˜¹', 'y': 'ğ˜º', 'z': 'ğ˜»',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ¢', '1': 'ğŸ£', '2': 'ğŸ¤', '3': 'ğŸ¥', '4': 'ğŸ¦',
        '5': 'ğŸ§', '6': 'ğŸ¨', '7': 'ğŸ©', '8': 'ğŸª', '9': 'ğŸ«',

    }

    # sans serif bold
    mathbfsf_map = {
        # upper case

        'A': 'ğ—”', 'B': 'ğ—•', 'C': 'ğ—–', 'D': 'ğ——', 'E': 'ğ—˜',
        'F': 'ğ—™', 'G': 'ğ—š', 'H': 'ğ—›', 'I': 'ğ—œ', 'J': 'ğ—',
        'K': 'ğ—', 'L': 'ğ—Ÿ', 'M': 'ğ— ', 'N': 'ğ—¡', 'O': 'ğ—¢',
        'P': 'ğ—£', 'Q': 'ğ—¤', 'R': 'ğ—¥', 'S': 'ğ—¦', 'T': 'ğ—§',
        'U': 'ğ—¨', 'V': 'ğ—©', 'W': 'ğ—ª', 'X': 'ğ—«', 'Y': 'ğ—¬', 'Z': 'ğ—­',

        # lower case
        'a': 'ğ—®', 'b': 'ğ—¯', 'c': 'ğ—°', 'd': 'ğ—±', 'e': 'ğ—²',
        'f': 'ğ—³', 'g': 'ğ—´', 'h': 'ğ—µ', 'i': 'ğ—¶', 'j': 'ğ—·',
        'k': 'ğ—¸', 'l': 'ğ—¹', 'm': 'ğ—º', 'n': 'ğ—»', 'o': 'ğ—¼',
        'p': 'ğ—½', 'q': 'ğ—¾', 'r': 'ğ—¿', 's': 'ğ˜€', 't': 'ğ˜',
        'u': 'ğ˜‚', 'v': 'ğ˜ƒ', 'w': 'ğ˜„', 'x': 'ğ˜…', 'y': 'ğ˜†', 'z': 'ğ˜‡',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯', '4': 'ğŸ°',
        '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ',

        # Greek
        # Greek Letters (Uppercase)
        'Î‘': 'ğ–', 'Î’': 'ğ—', 'Î“': 'ğ˜', 'Î”': 'ğ™', 'Î•': 'ğš', 'Î–': 'ğ›', 
        'Î—': 'ğœ', 'Î˜': 'ğ', 'Î™': 'ğ', 'Îš': 'ğŸ',  'Î›': 'ğ ', 'Îœ': 'ğ¡',
        'Î': 'ğ¢', 'Î': 'ğ£', 'ÎŸ': 'ğ¤', 'Î ': 'ğ¥', 'Î¡': 'ğ¦', 'Ï´': 'ğ§',
        'Î£': 'ğ¨', 'Î¤': 'ğ©', 'Ï’': 'ğª', 'Î¦': 'ğ«', 'Î§': 'ğ¬', 'Î¨': 'ğ­',
        'Î©': 'ğ®', 'âˆ‡': 'ğ¯',

        # Greek Letters (Lowercase)
        'Î±': 'ğ°', 'Î²': 'ğ±', 'Î³': 'ğ²', 'Î´': 'ğ³', 'Îµ': 'ğ´', 'Î¶': 'ğµ',
        'Î·': 'ğ¶', 'Î¸': 'ğ·', 'Î¹': 'ğ¸', 'Îº': 'ğ¹', 'Î»': 'ğº', 'Î¼': 'ğ»', 
        'Î½': 'ğ¼', 'Î¾': 'ğ½', 'Î¿': 'ğ¾', 'Ï€': 'ğ¿', 'Ï': 'ğ€', 'Ï‚': 'ğ',
        'Ïƒ': 'ğ‚', 'Ï„': 'ğƒ', 'Ï…': 'ğ„', 'Ï†': 'ğ…', 'Ï‡': 'ğ†', 'Ïˆ': 'ğ‡',
        'Ï‰': 'ğˆ',
        'âˆ‚': 'ğ‰', 'Ïµ': 'ğŠ',




    }

    # sans serif bold italic
    mathbfsfit_map = {
        # upper case

        'A': 'ğ˜¼', 'B': 'ğ˜½', 'C': 'ğ˜¾', 'D': 'ğ˜¿', 'E': 'ğ™€',
        'F': 'ğ™', 'G': 'ğ™‚', 'H': 'ğ™ƒ', 'I': 'ğ™„', 'J': 'ğ™…',
        'K': 'ğ™†', 'L': 'ğ™‡', 'M': 'ğ™ˆ', 'N': 'ğ™‰', 'O': 'ğ™Š',
        'P': 'ğ™‹', 'Q': 'ğ™Œ', 'R': 'ğ™', 'S': 'ğ™', 'T': 'ğ™',
        'U': 'ğ™', 'V': 'ğ™‘', 'W': 'ğ™’', 'X': 'ğ™“', 'Y': 'ğ™”', 'Z': 'ğ™•',

        # lower case
        'a': 'ğ™–', 'b': 'ğ™—', 'c': 'ğ™˜', 'd': 'ğ™™', 'e': 'ğ™š',
        'f': 'ğ™›', 'g': 'ğ™œ', 'h': 'ğ™', 'i': 'ğ™', 'j': 'ğ™Ÿ',
        'k': 'ğ™ ', 'l': 'ğ™¡', 'm': 'ğ™¢', 'n': 'ğ™£', 'o': 'ğ™¤',
        'p': 'ğ™¥', 'q': 'ğ™¦', 'r': 'ğ™§', 's': 'ğ™¨', 't': 'ğ™©',
        'u': 'ğ™ª', 'v': 'ğ™«', 'w': 'ğ™¬', 'x': 'ğ™­', 'y': 'ğ™®', 'z': 'ğ™¯',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯', '4': 'ğŸ°',
        '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ',

        # Greek
        # Greek Letters (Uppercase)
        'Î‘': 'ğ', 'Î’': 'ğ‘', 'Î“': 'ğ’', 'Î”': 'ğ“', 'Î•': 'ğ”', 'Î–': 'ğ•', 
        'Î—': 'ğ–', 'Î˜': 'ğ—', 'Î™': 'ğ˜', 'Îš': 'ğ™',  'Î›': 'ğš', 'Îœ': 'ğ›',
        'Î': 'ğœ', 'Î': 'ğ', 'ÎŸ': 'ğ', 'Î ': 'ğŸ', 'Î¡': 'ğ ', 'Ï´': 'ğ¡',
        'Î£': 'ğ¢', 'Î¤': 'ğ£', 'Ï’': 'ğ¤', 'Î¦': 'ğ¥', 'Î§': 'ğ¦', 'Î¨': 'ğ§',
        'Î©': 'ğ¨', 'âˆ‡': 'ğ©',

        # Greek Letters (Lowercase)
        'Î±': 'ğª', 'Î²': 'ğ«', 'Î³': 'ğ¬', 'Î´': 'ğ­', 'Îµ': 'ğ®', 'Î¶': 'ğ¯',
        'Î·': 'ğ°', 'Î¸': 'ğ±', 'Î¹': 'ğ²', 'Îº': 'ğ³', 'Î»': 'ğ´', 'Î¼': 'ğµ', 
        'Î½': 'ğ¶', 'Î¾': 'ğ·', 'Î¿': 'ğ¸', 'Ï€': 'ğ¹', 'Ï': 'ğº', 'Ï‚': 'ğ»',
        'Ïƒ': 'ğ¼', 'Ï„': 'ğ½', 'Ï…': 'ğ¾', 'Ï†': 'ğ¿', 'Ï‡': 'ğŸ€', 'Ïˆ': 'ğŸ',
        'Ï‰': 'ğŸ‚',
        'âˆ‚': 'ğŸƒ', 'Ïµ': 'ğŸ„',




    }

    # bold italic
    mathbfit_map = {
        # upper case

        'A': 'ğ‘¨', 'B': 'ğ‘©', 'C': 'ğ‘ª', 'D': 'ğ‘«', 'E': 'ğ‘¬',
        'F': 'ğ‘­', 'G': 'ğ‘®', 'H': 'ğ‘¯', 'I': 'ğ‘°', 'J': 'ğ‘±',
        'K': 'ğ‘²', 'L': 'ğ‘³', 'M': 'ğ‘´', 'N': 'ğ‘µ', 'O': 'ğ‘¶',
        'P': 'ğ‘·', 'Q': 'ğ‘¸', 'R': 'ğ‘¹', 'S': 'ğ‘º', 'T': 'ğ‘»',
        'U': 'ğ‘¼', 'V': 'ğ‘½', 'W': 'ğ‘¾', 'X': 'ğ‘¿', 'Y': 'ğ’€', 'Z': 'ğ’',

        # lower case
        'a': 'ğ’‚', 'b': 'ğ’ƒ', 'c': 'ğ’„', 'd': 'ğ’…', 'e': 'ğ’†',
        'f': 'ğ’‡', 'g': 'ğ’ˆ', 'h': 'ğ’‰', 'i': 'ğ’Š', 'j': 'ğ’‹',
        'k': 'ğ’Œ', 'l': 'ğ’', 'm': 'ğ’', 'n': 'ğ’', 'o': 'ğ’',
        'p': 'ğ’‘', 'q': 'ğ’’', 'r': 'ğ’“', 's': 'ğ’”', 't': 'ğ’•',
        'u': 'ğ’–', 'v': 'ğ’—', 'w': 'ğ’˜', 'x': 'ğ’™', 'y': 'ğ’š', 'z': 'ğ’›',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯', '4': 'ğŸ°',
        '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ',

        # Greek
        # Greek Letters (Uppercase)
        'Î‘': 'ğœœ', 'Î’': 'ğœ', 'Î“': 'ğœ', 'Î”': 'ğœŸ', 'Î•': 'ğœ ', 'Î–': 'ğœ¡', 
        'Î—': 'ğœ¢', 'Î˜': 'ğœ£', 'Î™': 'ğœ¤', 'Îš': 'ğœ¥',  'Î›': 'ğœ¦', 'Îœ': 'ğœ§',
        'Î': 'ğœ¨', 'Î': 'ğœ©', 'ÎŸ': 'ğœª', 'Î ': 'ğœ«', 'Î¡': 'ğœ¬', 'Ï´': 'ğœ­',
        'Î£': 'ğœ®', 'Î¤': 'ğœ¯', 'Ï’': 'ğœ°', 'Î¦': 'ğœ±', 'Î§': 'ğœ²', 'Î¨': 'ğœ³',
        'Î©': 'ğœ´', 'âˆ‡': 'ğœµ',

        # Greek Letters (Lowercase)
        'Î±': 'ğœ¶', 'Î²': 'ğœ·', 'Î³': 'ğœ¸', 'Î´': 'ğœ¹', 'Îµ': 'ğœº', 'Î¶': 'ğœ»',
        'Î·': 'ğœ¼', 'Î¸': 'ğœ½', 'Î¹': 'ğœ¾', 'Îº': 'ğœ¿', 'Î»': 'ğ€', 'Î¼': 'ğ', 
        'Î½': 'ğ‚', 'Î¾': 'ğƒ', 'Î¿': 'ğ„', 'Ï€': 'ğ…', 'Ï': 'ğ†', 'Ï‚': 'ğ‡',
        'Ïƒ': 'ğˆ', 'Ï„': 'ğ‰', 'Ï…': 'ğŠ', 'Ï†': 'ğ‹', 'Ï‡': 'ğŒ', 'Ïˆ': 'ğ',
        'Ï‰': 'ğ',
        'âˆ‚': 'ğ', 'Ïµ': 'ğ',
    }

    # for \symup - relly just a NOP
    math_upright_map = {
        # Uppercase Latin
        'A': 'A', 'B': 'B', 'C': 'C', 'D': 'D', 'E': 'E', 'F': 'F', 'G': 'G',
        'H': 'H', 'I': 'I', 'J': 'J', 'K': 'K', 'L': 'L', 'M': 'M', 'N': 'N',
        'O': 'O', 'P': 'P', 'Q': 'Q', 'R': 'R', 'S': 'S', 'T': 'T', 'U': 'U',
        'V': 'V', 'W': 'W', 'X': 'X', 'Y': 'Y', 'Z': 'Z',

        # Lowercase Latin
        'a': 'a', 'b': 'b', 'c': 'c', 'd': 'd', 'e': 'e', 'f': 'f', 'g': 'g',
        'h': 'h', 'i': 'i', 'j': 'j', 'k': 'k', 'l': 'l', 'm': 'm', 'n': 'n',
        'o': 'o', 'p': 'p', 'q': 'q', 'r': 'r', 's': 's', 't': 't', 'u': 'u',
        'v': 'v', 'w': 'w', 'x': 'x', 'y': 'y', 'z': 'z',

        # Digits
        '0': '0', '1': '1', '2': '2', '3': '3', '4': '4',
        '5': '5', '6': '6', '7': '7', '8': '8', '9': '9',

        # Greek Uppercase Upright
        'Î‘': 'Î‘', 'Î’': 'Î’', 'Î“': 'Î“', 'Î”': 'Î”', 'Î•': 'Î•', 'Î–': 'Î–', 'Î—': 'Î—',
        'Î˜': 'Î˜', 'Î™': 'Î™', 'Îš': 'Îš', 'Î›': 'Î›', 'Îœ': 'Îœ', 'Î': 'Î', 'Î': 'Î',
        'ÎŸ': 'ÎŸ', 'Î ': 'Î ', 'Î¡': 'Î¡', 'Î£': 'Î£', 'Î¤': 'Î¤', 'Î¥': 'Î¥', 'Î¦': 'Î¦',
        'Î§': 'Î§', 'Î¨': 'Î¨', 'Î©': 'Î©',

        # Greek Lowercase Upright
        'Î±': 'Î±', 'Î²': 'Î²', 'Î³': 'Î³', 'Î´': 'Î´', 'Îµ': 'Îµ', 'Î¶': 'Î¶', 'Î·': 'Î·',
        'Î¸': 'Î¸', 'Î¹': 'Î¹', 'Îº': 'Îº', 'Î»': 'Î»', 'Î¼': 'Î¼', 'Î½': 'Î½', 'Î¾': 'Î¾',
        'Î¿': 'Î¿', 'Ï€': 'Ï€', 'Ï': 'Ï', 'Ïƒ': 'Ïƒ', 'Ï„': 'Ï„', 'Ï…': 'Ï…', 'Ï†': 'Ï†',
        'Ï‡': 'Ï‡', 'Ïˆ': 'Ïˆ', 'Ï‰': 'Ï‰',
    }

    # For \symit (Italic)
    math_italic_map = {
        'A': 'ğ´', 'B': 'ğµ', 'C': 'ğ¶', 'D': 'ğ·', 'E': 'ğ¸', 'F': 'ğ¹', 'G': 'ğº', 'H': 'ğ»',
        'I': 'ğ¼', 'J': 'ğ½', 'K': 'ğ¾', 'L': 'ğ¿', 'M': 'ğ‘€', 'N': 'ğ‘', 'O': 'ğ‘‚', 'P': 'ğ‘ƒ',
        'Q': 'ğ‘„', 'R': 'ğ‘…', 'S': 'ğ‘†', 'T': 'ğ‘‡', 'U': 'ğ‘ˆ', 'V': 'ğ‘‰', 'W': 'ğ‘Š', 'X': 'ğ‘‹',
        'Y': 'ğ‘Œ', 'Z': 'ğ‘',
        'a': 'ğ‘', 'b': 'ğ‘', 'c': 'ğ‘', 'd': 'ğ‘‘', 'e': 'ğ‘’', 'f': 'ğ‘“', 'g': 'ğ‘”', 'h': 'â„',
        'i': 'ğ‘–', 'j': 'ğ‘—', 'k': 'ğ‘˜', 'l': 'ğ‘™', 'm': 'ğ‘š', 'n': 'ğ‘›', 'o': 'ğ‘œ', 'p': 'ğ‘',
        'q': 'ğ‘', 'r': 'ğ‘Ÿ', 's': 'ğ‘ ', 't': 'ğ‘¡', 'u': 'ğ‘¢', 'v': 'ğ‘£', 'w': 'ğ‘¤', 'x': 'ğ‘¥',
        'y': 'ğ‘¦', 'z': 'ğ‘§',
        'Î‘': '\u1D6E2', 'Î’': '\u1D6E3', 'Î“': '\u1D6E4', 'Î”': '\u1D6E5', 'Î•': '\u1D6E6', 'Î–': '\u1D6E7',
        'Î—': '\u1D6E8', 'Î˜': '\u1D6E9', 'Î™': '\u1D6EA', 'Îš': '\u1D6EB', 'Î›': '\u1D6EC', 'Îœ': '\u1D6ED',
        'Î': '\u1D6EE', 'Î': '\u1D6EF', 'ÎŸ': '\u1D6F0', 'Î ': '\u1D6F1', 'Î¡': '\u1D6F2', 'Ï´': '\u1D6F3',
        'Î£': '\u1D6F4', 'Î¤': '\u1D6F5', 'Î¥': '\u1D6F6', 'Î¦': '\u1D6F7', 'Î§': '\u1D6F8', 'Î¨': '\u1D6F9',
        'Î©': '\u1D6FA', 'âˆ‡': '\u1D6FB',
        'Î±': '\u1D6FC', 'Î²': '\u1D6FD', 'Î³': '\u1D6FE', 'Î´': '\u1D6FF', 'Îµ': '\u1D700', 'Î¶': '\u1D701',
        'Î·': '\u1D702', 'Î¸': '\u1D703', 'Î¹': '\u1D704', 'Îº': '\u1D705', 'Î»': '\u1D706', 'Î¼': '\u1D707',
        'Î½': '\u1D708', 'Î¾': '\u1D709', 'Î¿': '\u1D70A', 'Ï€': '\u1D70B', 'Ï': '\u1D70C', 'Ï‚': '\u1D70D',
        'Ïƒ': '\u1D70E', 'Ï„': '\u1D70F', 'Ï…': '\u1D710', 'Ï†': '\u1D711', 'Ï‡': '\u1D712', 'Ïˆ': '\u1D713',
        'Ï‰': '\u1D714',
        'âˆ‚': '\u1D715', 'Ïµ': '\u1D716',
    }

    # For \symbf (Bold)
    math_bold_map = {
        'A': 'ğ€', 'B': 'ğ', 'C': 'ğ‚', 'D': 'ğƒ', 'E': 'ğ„', 'F': 'ğ…', 'G': 'ğ†', 'H': 'ğ‡',
        'I': 'ğˆ', 'J': 'ğ‰', 'K': 'ğŠ', 'L': 'ğ‹', 'M': 'ğŒ', 'N': 'ğ', 'O': 'ğ', 'P': 'ğ',
        'Q': 'ğ', 'R': 'ğ‘', 'S': 'ğ’', 'T': 'ğ“', 'U': 'ğ”', 'V': 'ğ•', 'W': 'ğ–', 'X': 'ğ—',
        'Y': 'ğ˜', 'Z': 'ğ™',
        'a': 'ğš', 'b': 'ğ›', 'c': 'ğœ', 'd': 'ğ', 'e': 'ğ', 'f': 'ğŸ', 'g': 'ğ ', 'h': 'ğ¡',
        'i': 'ğ¢', 'j': 'ğ£', 'k': 'ğ¤', 'l': 'ğ¥', 'm': 'ğ¦', 'n': 'ğ§', 'o': 'ğ¨', 'p': 'ğ©',
        'q': 'ğª', 'r': 'ğ«', 's': 'ğ¬', 't': 'ğ­', 'u': 'ğ®', 'v': 'ğ¯', 'w': 'ğ°', 'x': 'ğ±',
        'y': 'ğ²', 'z': 'ğ³',
        'Î‘': '\u1D6A8', 'Î’': '\u1D6A9', 'Î“': '\u1D6AA', 'Î”': '\u1D6AB', 'Î•': '\u1D6AC', 'Î–': '\1D6AD',
        'Î—': '\u1D6AE', 'Î˜': '\u1D6AF', 'Î™': '\u1D6B0', 'Îš': '\u1D6B1', 'Î›': '\u1D6B2', 'Îœ': '\u1D6B3',
        'Î': '\u1D6B4', 'Î': '\u1D6B5', 'ÎŸ': '\u1D6B6', 'Î ': '\u1D6B7', 'Î¡': '\u1D6B8', 'Î¸': 'u1D6B9',
        'Î£': '\u1D6BA', 'Î¤': '\u1D6BB', 'Î¥': '\u1D6BC', 'Î¦': '\u1D6BD', 'Î§': '\u1D6BE', 'Î¨': '\u1D6B',
        'Î©': '\u1D6C0', 'âˆ‡': '\u1D6C1',
        'Î±': '\u1D6C2', 'Î²': '\u1D6C3', 'Î³': '\u1D6C4', 'Î´': '\u1D6C5', 'Îµ': '\u1D6C6', 'Î¶': '\u1D6C7',
        'Î·': '\u1D6C8', 'Î¸': '\u1D6C9', 'Î¹': '\u1D6CA', 'Îº': '\u1D6CB', 'Î»': '\u1D6CC', 'Î¼': '\u1D6CD',
        'Î½': '\u1D6CE', 'Î¾': '\u1D6CF', 'Î¿': '\u1D6D0', 'Ï€': '\u1D6D1', 'Ï': '\u1D6D2', 'Ï‚': '\u1D6D3',
        'Ïƒ': '\u1D6D4', 'Ï„': '\u1D6D5', 'Ï…': '\u1D6D6', 'Ï†': '\u1D6D7', 'Ï‡': '\u1D6D8', 'Ïˆ': '\u1D6D9',
        'Ï‰': '\u1D6DA', 'âˆ‚': '\u1D6DB', 'Ïµ': '\u1D6DC',

        # digits - these are all "Mathematical Bold Digit"
        '0': 'ğŸ¬', '1': 'ğŸ­', '2': 'ğŸ®', '3': 'ğŸ¯', '4': 'ğŸ°',
        '5': 'ğŸ±', '6': 'ğŸ²', '7': 'ğŸ³', '8': 'ğŸ´', '9': 'ğŸµ',

    }

    # For \symsf (sans-serif)
    math_sans_map = {
        'A': '\u1D5A0', 'B': '\u1D5A1', 'C': '\u1D5A2', 'D': '\u1D5A3', 'E': '\u1D5A4',
        'F': '\u1D5A5', 'G': '\u1D5A6', 'H': '\u1D5A7', 'I': '\u1D5A8', 'J': '\u1D5A9',
        'K': '\u1D5AA', 'L': '\u1D5AB', 'M': '\u1D5AC', 'N': '\u1D5AD', 'O': '\u1D5AE',
        'P': '\u1D5AF', 'Q': '\u1D5B0', 'R': '\u1D5B1', 'S': '\u1D5B2', 'T': '\u1D5B3',
        'U': '\u1D5B4', 'V': '\u1D5B5', 'W': '\u1D5B6', 'X': '\u1D5B7', 'Y': '\u1D5B8', 'Z': '\u1D5B9',
        'a': '\u1D5BA', 'b': '\u1D5BB', 'c': '\u1D5BC', 'd': '\u1D5BD', 'e': '\u1D5BE',
        'f': '\u1D5BF', 'g': '\u1D5C0', 'h': '\u1D5C1', 'i': '\u1D5C2', 'j': '\u1D5C3',
        'k': '\u1D5C4', 'l': '\u1D5C5', 'm': '\u1D5C6', 'n': '\u1D5C7', 'o': '\u1D5C8',
        'p': '\u1D5C9', 'q': '\u1D5CA', 'r': '\u1D5CB', 's': '\u1D5CC', 't': '\u1D5CD',
        'u': '\u1D5CE', 'v': '\u1D5CF', 'w': '\u1D5D0', 'x': '\u1D5D1', 'y': '\u1D5D2', 'z': '\u1D5D3',

        # digits - these are all "Mathematical Bold Digit"
        '0': '\u1D7E2', '1': '\u1D7E3', '2': '\u1D7E4', '3': '\u1D7E5', '4': '\u1D7E6',
        '5': '\u1D7E7', '6': '\u1D7E8', '7': '\u1D7E9', '8': '\u1D7EA', '9': '\u1D7EB',

    }

    # For \symtt (mono)
    math_mono_map = {
        'A': '\u1D670', 'B': '\u1D671', 'C': '\u1D672', 'D': '\u1D673', 'E': '\u1D674',
        'F': '\u1D675', 'G': '\u1D676', 'H': '\u1D677', 'I': '\u1D678', 'J': '\u1D679',
        'K': '\u1D67A', 'L': '\u1D67B', 'M': '\u1D67C', 'N': '\u1D67D', 'O': '\u1D67E',
        'P': '\u1D67F', 'Q': '\u1D680', 'R': '\u1D681', 'S': '\u1D682', 'T': '\u1D683',
        'U': '\u1D684', 'V': '\u1D685', 'W': '\u1D686', 'X': '\u1D687', 'Y': '\u1D688', 'Z': '\u1D689',
        'a': '\u1D68A', 'b': '\u1D68B', 'c': '\u1D68C', 'd': '\u1D68D', 'e': '\u1D68E',
        'f': '\u1D68F', 'g': '\u1D690', 'h': '\u1D691', 'i': '\u1D692', 'j': '\u1D693',
        'k': '\u1D694', 'l': '\u1D695', 'm': '\u1D696', 'n': '\u1D697', 'o': '\u1D698',
        'p': '\u1D699', 'q': '\u1D69A', 'r': '\u1D69B', 's': '\u1D69C', 't': '\u1D69D',
        'u': '\u1D69E', 'v': '\u1D69F', 'w': '\u1D6A0', 'x': '\u1D6A1', 'y': '\u1D6A2', 'z': '\u1D6A3',

        # digits - these are all "Mathematical Bold Digit"
        '0': '\u1D7F6', '1': '\u1D7F7', '2': '\u1D7F8', '3': '\u1D7F9', '4': '\u1D7FA',
        '5': '\u1D7FB', '6': '\u1D7FC', '7': '\u1D7FD', '8': '\u1D7FE', '9': '\u1D7FF',

    }


    # 2. Create a master dictionary mapping the command to its character table.
    math_alphabet_commands = {
        '\\symup': math_upright_map,
        '\\symit': math_italic_map,
        '\\symbf': math_bold_map,
        '\\symsf': math_sans_map,
        '\\symtt': math_mono_map,

        '\\mathbb': mathbb_map,
        '\\symbb': mathbb_map,  # new unicode-math command

        '\\mathbbit': mathbbit_map,
        '\\symbbit': mathbbit_map,


        '\\mathds': mathbb_map, # this uses another font, but maps to the same unicode codepoints

        '\\mathcal': mathcal_map,
        '\\symcal': mathcal_map,
        '\\symbfcal': mathcalbold_map,
        '\\mathbfcal': mathcalbold_map,

        
        '\\mathscr': mathscr_map,
        '\\symscr': mathscr_map,
        '\\symbfscr': mathscrbold_map,
        '\\mathbfscr': mathscrbold_map,


        '\\mathfrak': mathfrak_map,
        '\\symfrak': mathfrak_map,
        '\\textfrak': mathfrak_map,

        '\\mbfrak':   mbfrak_map,
        '\\symbffrak':  mbfrak_map,
        '\\mathbffrak':  mbfrak_map,

        '\\mathsf': mathsf_map,
        '\\symsf': mathsf_map,
        '\\symsfit': mathsfit_map,
        '\\mathsfit':  mathsfit_map,
        '\\mathbfsf': mathbfsf_map,
        '\\symbfsf': mathbfsf_map,

        '\\mathbfit': mathbfit_map,
        '\\symbfit': mathbfit_map,

        # Add other alphabets if needed

    }

    # 3. Iterate through the commands and perform the replacements.
    for command, char_map in math_alphabet_commands.items():
        escaped_command = re.escape(command)
        # Pattern finds the command and captures the single letter in braces.
        pattern = escaped_command + r'\s*\{([A-Za-z])\}'
        
        def replacer(match):
            char_to_replace = match.group(1)
            # Look up the captured letter in the correct character map.
            # If not found, return the original full match to be safe.
            return char_map.get(char_to_replace, match.group(0))

        s = re.sub(pattern, replacer, s)
        
    return s

def convert_latex_math_to_unicode(s):
    """
    Converts a wider range of LaTeX math commands found in titles
    to their Unicode equivalents.
    """
    s = s.replace("'''", "â€´") # Triple Prime (U+2034)
    s = s.replace("''", "â€³")  # Double Prime (U+2033)
    s = s.replace("'", "â€²")   # Prime (U+2032)
    s=s.replace('\\to,', 'â†’')   # Rightwards Arrow - &rightarrow;



    # 1. A much more comprehensive mapping for Greek letters and common symbols.
    symbol_map = {
        # Greek Letters (Uppercase)
        '\\Gamma': 'Î“', '\\Delta': 'Î”', '\\Theta': 'Î˜', '\\Lambda': 'Î›',
        '\\Xi': 'Î', '\\Pi': 'Î ', '\\Sigma': 'Î£',
        #'\\Upsilon': 'Î¥', # Incorrect: Standard Greek Upsilon (U+03A5)
        '\\Upsilon': 'Ï’',  # Correct: Greek Upsilon with hook symbol (U+03D2)
        '\\Phi': 'Î¦', '\\Psi': 'Î¨', '\\Omega': 'Î©', '\\nabla': 'âˆ‡', '\\Theta': 'Î˜',
        # Greek Letters (Lowercase)
        '\\alpha': 'Î±', '\\beta': 'Î²', '\\gamma': 'Î³', '\\delta': 'Î´',
        '\\epsilon': 'Îµ', '\\varepsilon': 'Ïµ', '\\zeta': 'Î¶', '\\eta': 'Î·',
        '\\theta': 'Î¸', '\\vartheta': 'Ï‘', '\\iota': 'Î¹', '\\kappa': 'Îº',
        '\\lambda': 'Î»', '\\mu': 'Î¼', '\\nu': 'Î½', '\\xi': 'Î¾',
        '\\pi': 'Ï€', '\\varpi': 'Ï–', '\\rho': 'Ï', '\\varrho': 'Ï±',
        '\\sigma': 'Ïƒ', '\\varsigma': 'Ï‚', '\\tau': 'Ï„', '\\upsilon': 'Ï…',
        '\\phi': 'Ï†', '\\varphi': 'Ï•', '\\chi': 'Ï‡', '\\psi': 'Ïˆ',
        '\\omega': 'Ï‰',  '\\theta': 'Î¸',

        # script l (used for leptons)
        '\\ell': 'â„“',
        # Common Math Symbols
        '\\pm': 'Â±', '\\times': 'Ã—', '\\div': 'Ã·',
        '\\leq': 'â‰¤', '\\geq': 'â‰¥', '\\neq': 'â‰ ',
        '\\approx': 'â‰ˆ', '\\sim': 'âˆ¼', '\\infty': 'âˆ',
        '\\ldots': 'â€¦', '\\cdot': 'Â·', '\\circ': 'â—¦',
        '\\in': 'âˆˆ', '\\otimes': 'âŠ—', '\\oplus': 'âŠ•',
        '\\sum': 'âˆ‘', '\\prod': 'âˆ', '\\sqrt': 'âˆš', # Handle sqrt with arg separately if needed
        '\\prime': "â€²",   # Prime (U+2032)
        '\\dprime': "â€³",  # Double Prime (U+2033)
        '\\prime': "â€´",   # Triple Prime (U+2034)
    }

    # Mappings for superscripts and subscripts
    superscript_map = {
        # Digits
        '0': 'â°', '1': 'Â¹', '2': 'Â²', '3': 'Â³', '4': 'â´', '5': 'âµ', '6': 'â¶', '7': 'â·', '8': 'â¸', '9': 'â¹',

        # Punctuation & Operators
        '+': 'âº', # 	U+207A
        '-': 'â»', #	U+207B
        '=': 'â¼', #	U+207C
        '(': 'â½', #	U+207D
        ')': 'â¾', #	U+207E

        # Uppercase Latin
        'A': 'á´¬', #	U+1D2C
        'B': 'á´®', #	U+1D2E
        # C is missing
        'D': 'á´°', #	U+1D30
        'E': 'á´±', #	U+1D31
        # F is missing
        'G': 'á´³', #	U+1D33
        'H': 'á´´', #	U+1D34
        'I': 'á´µ', #	U+1D35
        'J': 'á´¶', #	U+1D36
        'K': 'á´·', #	U+1D37
        'L': 'á´¸', #	U+1D38
        'M': 'á´¹', #	U+1D39
        'N': 'á´º', #	U+1D3A
        'O': 'á´¼', #	U+1D3C
        'P': 'á´¾', #	U+1D3E
        # Q is missing
        'R': 'á´¿', #	U+1D3F
        # S is missing
        'T': 'áµ€', #	U+1D40
        'U': 'áµ', #	U+1D41
        # V is mssing
        'W': 'áµ‚', #	U+1D42
        # X, Y, and Z are missing


        # Lowercase Latin
        'a': 'áµƒ', #	U+1D43
        'b': 'áµ‡', #	U+1D47
        'c': 'á¶œ', #	U+1D9C
        'd': 'áµˆ', #	U+1D48
        'e': 'áµˆ', #	U+1D48
        'f': 'á¶ ', #	U+1DA0
        'g': 'áµ', #	U+1D4D
        'h': 'Ê°', #	U+02B0
        'i': 'â±', #	U+2071
        'j': 'Ê²', #	U+02B2
        'k': 'áµ', #	U+1D4F
        'l': 'Ë¡', #	U+02E1
        'm': 'áµ', #	U+1D50
        'n': 'â¿', #	U+207F
        'o': 'áµ’', #	U+1D52
        'p': 'áµ–', #	U+1D56
        # q is missing
        'r': 'Ê³', #	U+02B3
        's': 'Ë¢', #	U+02E2
        't': 'áµ—', #	U+1D57
        'u': 'áµ˜', #	U+1D58
        'v': 'áµ›', #	U+1D5B
        'w': 'Ê·', #	U+02B7
        'x': 'Ë£', #	U+02E3
        'y': 'Ê¸', #	U+02B8
        'z': 'á¶»', #	U+1DBB

        # Greek
        'Î±': 'áµ…', #	U+1D45
        'Î²': 'áµ', #	U+1D5D
        'Î³': 'áµ', #	U+1D5E
        'Î´': 'áµŸ', #	U+1D5F
        'Ï†': 'áµ ', #	U+1D60
        'Ï‡': 'áµ¡', #	U+1D61
    }

    subscript_map   = {
        # Digits
        '0': 'â‚€', '1': 'â‚', '2': 'â‚‚', '3': 'â‚ƒ', '4': 'â‚„', '5': 'â‚…', '6': 'â‚†', '7': 'â‚‡', '8': 'â‚ˆ', '9': 'â‚‰',

        # Punctuation & Operators
        '+': 'â‚Š', #	U+208A
        '-': 'â‚‹', #	U+208B
        '=': 'â‚Œ', #	U+208C
        '(': 'â‚', #	U+208D
        ')': 'â‚', #	U+208E

        # Lowercase Latin
        'a': 'â‚', #	U+2090
        'e': 'â‚‘', #	U+2091
        'h': 'â‚•', #	U+2095
        'i': 'áµ¢', #	U+1D62
        'j': 'â±¼', #	U+2C7C
        'k': 'â‚–', #	U+2096
        'l': 'â‚—', #	U+2097
        'm': 'â‚˜', #	U+2098
        'n': 'â‚™', #	U+2099
        'o': 'â‚’', #	U+2092
        'p': 'â‚š', #	U+209A
        'r': 'áµ£', #	U+1D63
        's': 'â‚›', #	U+209B
        't': 'â‚œ', #	U+209C
        'u': 'áµ¤', #	U+1D64
        'v': 'áµ¥', #	U+1D65
        'x': 'â‚“', #	U+2093

        # Greek
        'Î²': 'áµ¦', #	U+1D66
        'Î³': 'áµ§', #	U+1D67
        'Ï': 'áµ¨', #	U+1D68
        'Ï†': 'áµ©', #	U+1D69
        'Ï‡': 'áµª', #	U+1D6A
    }

    # Replace simple, no-argument commands first
    for command, unicode_char in symbol_map.items():
        s = s.replace(command, unicode_char)

    # Replace superscripts
    def sup_replacer(match):
        content = match.group(1)
        # Try to use the Unicode map first
        unicode_chars = [superscript_map.get(char, None) for char in content]
        if all(unicode_chars):
            return "".join(unicode_chars)
        # If any character is not in the map, fall back to HTML tags
        else:
            return f'<sup>{content}</sup>'
    s = re.sub(r'\^\{?([^}]+)\}?', sup_replacer, s)

    # Replace subscripts
    def sub_replacer(match):
        content = match.group(1)
        unicode_chars = [subscript_map.get(char, None) for char in content]
        if all(unicode_chars):
            return "".join(unicode_chars)
        else:
            return f'<sub>{content}</sub>'
    s = re.sub(r'\_\{?([^}]+)\}?', sub_replacer, s)
    
    # Handle math alphabets
    s = replace_math_alphabets(s)

    # Remove any remaining math delimiters
    s = s.replace('$', '')
    
    return s



def clean_up_abstract(s):
    #print(f"in clean_up_abstract abstract={s}")
    s='<p>'+s+'</p>'
    
    s = process_latex_in_blocks(s)

    return s



def check_for_acronyms(a):
    if (a.find('\\gls{') >= 0) or (a.find('\\glspl{') >= 0) or \
       (a.find('\\Gls{') >= 0) or (a.find('\\Glspl{') >= 0) or \
       (a.find('\\acrlong{') >= 0) or (a.find('\\acrshort{') >= 0) or \
       (a.find('\\glsentrylong') >= 0) or (a.find('\\glsentryshort{') >= 0) or (a.find('\\glsentryfull{') >= 0) or \
       (a.find('\\acrfull{') >= 0):
        return True
    return False

def get_acronyms_regex_with_errors(acronyms_filename):
    """
    Parses an acronyms file using a regular expression and reports
    any lines that appear to be definitions but cannot be parsed.
    """
    acronym_dict = {}
    
    # This pattern finds the command, ignores the optional [...], and captures the 3 arguments
    pattern = re.compile(r'\\newacronym(?:\[.*?\])?\{([^}]+)\}\{([^}]+)\}\{([^}]+)\}')
    
    try:
        with open(acronyms_filename, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                # We only care about lines that are likely to be definitions
                if '\\newacronym' in line:
                    # Strip comments from the line before matching
                    line_content = line.split('%')[0]
                    
                    match = pattern.search(line_content)
                    if match:
                        label, acronym, phrase = match.groups()
                        acronym_dict[label] = {'acronym': acronym, 'phrase': phrase}
                    else:
                        # If the line contains the command but doesn't match, it's a syntax error
                        print(f"Warning: Could not parse acronym definition on line {line_num}: {line.strip()}")
                        
    except FileNotFoundError:
        print(f"Error: Acronyms file not found at '{acronyms_filename}'")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None
        
    return acronym_dict

def old_get_acronyms(acronyms_filename):
    acronym_dict=dict()
    #
    newacronym_pattern='newacronym'
    trailing_marker='}'
    start_option_marker='['
    end_option_marker=']'
    #
    with open(acronyms_filename, 'r', encoding='utf-8') as input_FH:
        for line in input_FH:
            line=line.strip()   # remove leading and trailing white space
            comment_offset=line.find('%')
            if comment_offset == 1: #  of a comment line, simply skip the line
                continue
            offset=line.find(newacronym_pattern)
            if offset < 1:
                continue
            offset_s=line.find(start_option_marker)
            offset_e=line.find(end_option_marker)
            if offset_s > 0 and offset_e > 0: 		# remove options to \newacronym[options]{}{}{}
                line=line[0:offset_s]+line[offset_e+1:]
            # process an acronym definition
            parts=line.split('{')
            label=None
            acronym=None
            phrase=None
            for i, value in enumerate(parts):
                if i == 0:
                    continue
                elif i == 1: #  get label
                    label=value.strip()
                    if label.endswith(trailing_marker):
                        label=label[:-1]
                    else:
                        print("Error in parsing for label in line: {}".format(line))
                        continue
                elif i == 2: # get acronym
                    acronym=value.strip()
                    if acronym.endswith(trailing_marker):
                        acronym=acronym[:-1]
                    else:
                        print("Error in parsing for acronym in line: {}".format(line))
                        continue
                elif i == 3: # get phrase
                    phrase=value.strip()
                    if phrase.endswith(trailing_marker):
                        phrase=phrase[:-1]
                    else:
                        print("Error in parsing for phrase in line: {}".format(line))
                        continue
                else:
                    print("Error in parsing in line: {}".format(line))
                    continue
            acronym_dict[label]={'acronym': acronym, 'phrase': phrase}
            #
    return acronym_dict

def replace_first_gls(a, offset, acronym_dict):
    global spelled_out
    a_prefix=a[:offset]
    end_of_acronym=a.find('}', offset+5)
    if end_of_acronym < 0:
        print("could not find end of acronym label")
        return a
    label=a[offset+5:end_of_acronym]
    a_postfix=a[end_of_acronym+1:]
    ad=acronym_dict.get(label, None)
    if ad:
        phrase=ad.get('phrase', None)
        acronym=ad.get('acronym', None)
        already_spelled_out=spelled_out.get(label, None)
        if already_spelled_out:
            if acronym:
                a=a_prefix+acronym+a_postfix
            else:
                print("acronym missing for label={}".format(label))
        else:
            if phrase and acronym:
                full_phrase="{0} ({1})".format(phrase, acronym)
                a=a_prefix+full_phrase+a_postfix
                spelled_out[label]=True
            else:
                print("phrase or acronym are missing for label={}".format(label))
    else:
        print("Missing acronym for {}".format(label))
        return None
    #
    return a

def replace_first_glspl(a, offset, acronym_dict):
    global spelled_out
    a_prefix=a[:offset]
    end_of_acronym=a.find('}', offset+7)
    if end_of_acronym < 0:
        print("could not find end of acronym label")
        return a
    label=a[offset+7:end_of_acronym]
    a_postfix=a[end_of_acronym+1:]
    ad=acronym_dict.get(label, None)
    if ad:
        phrase=ad.get('phrase', None)
        acronym=ad.get('acronym', None)
        already_spelled_out=spelled_out.get(label, None)
        if already_spelled_out:
            if acronym:
                a=a_prefix+acronym+a_postfix
            else:
                print("acronym missing for label={}".format(label))
        else:
            if phrase and acronym:
                full_phrase="{0} ({1})".format(phrase, acronym)
                a=a_prefix+full_phrase+a_postfix
                spelled_out[label]=True
            else:
                print("phrase or acronym are missing for label={}".format(label))
    else:
        print("Missing acronym for {}".format(label))
        return None
    #
    return a

def spellout_acronyms_in_abstract(acronym_dict, a):
    # look for use of acronyms (i.e., a reference to an acronym's label) and spell out as needed
    # keep list of labels of acronyms found and spellout out
    global spelled_out
    spelled_out=dict()
    # Note that because we initialize it for each call of this routine, the acronyms will be spellout appropriately in each abstract
    #
    # first handle all cases where the full version is to be included
    for template in ['\\acrfull{', '\\glsentryfull{']:
        offset=a.find(template)
        while offset >= 0:
            a_prefix=a[:offset]
            end_of_acronym=a.find('}', offset+len(template))
            if end_of_acronym < 0:
                print("could not find end of acronym label")
                break
            label=a[offset+len(template):end_of_acronym]
            a_postfix=a[end_of_acronym+1:]
            ad=acronym_dict.get(label, None)
            if ad:
                phrase=ad.get('phrase', None)
                acronym=ad.get('acronym', None)
                if phrase and acronym:
                    full_phrase="{0} ({1})".format(phrase, acronym)
                    a=a_prefix+full_phrase+a_postfix
                    spelled_out[label]=True
                else:
                    print("phrase or acronym are missing for label={}".format(label))
            #
            offset=a.find(template, end_of_acronym)
    #
    # second handle all cases where the long version is to be included
    for template in ['\\acrlong{', '\\glsentrylong{']:
        offset=a.find(template)
        while offset >= 0:
            a_prefix=a[:offset]
            end_of_acronym=a.find('}', offset+len(template))
            if end_of_acronym < 0:
                print("could not find end of acronym label")
                break
            label=a[offset+len(template):end_of_acronym]
            a_postfix=a[end_of_acronym+1:]
            ad=acronym_dict.get(label, None)
            if ad:
                phrase=ad.get('phrase', None)
                if phrase:
                    a=a_prefix+phrase+a_postfix
                else:
                    print("phrase or acronym are missing for label={}".format(label))
            #
            offset=a.find(template, end_of_acronym)
    #
    #
    # third handle all cases where the long version is to be included
    for template in ['\\acrshort{', '\\glsentryshort{']:
        offset=a.find(template)
        while offset >= 0:
            a_prefix=a[:offset]
            end_of_acronym=a.find('}', offset+len(template))
            if end_of_acronym < 0:
                print("could not find end of acronym label")
                break
            label=a[offset+len(template):end_of_acronym]
            a_postfix=a[end_of_acronym+1:]
            ad=acronym_dict.get(label, None)
            if ad:
                acronym=ad.get('acronym', None)
                if acronym:
                    a=a_prefix+acronym+a_postfix
                else:
                    print("phrase or acronym are missing for label={}".format(label))
            #
            offset=a.find(template, end_of_acronym)
    #
    # handle cases where the acronym is conditionally spelled out and introduced or only the acronym is inserted
    # gls_offset=a.find('\\gls{')
    # lspl_offset=a.find('\\glspl{')
    # ggls_offset=a.find('\\Gls{')
    # gglspl_offset=a.find('\\Glspl{')
    # 
    s1=re.search('\\\\gls\{', a, re.IGNORECASE)
    s2=re.search('\\\\glspl\{', a, re.IGNORECASE)
    # find the earliest one
    while s1 or s2:
        if s1 and s2:
            gls_offset=s1.span()[0]
            glspl_offset=s2.span()[0]
            if  gls_offset < glspl_offset:
                # gls case occurs first
                a1=replace_first_gls(a, gls_offset, acronym_dict)
                if a1:
                    a=a1
                else:           # if the replacement failed, bail out
                    return a
            else:
                a=replace_first_glspl(a, glspl_offset, acronym_dict)
        elif s1 and not s2:
            gls_offset=s1.span()[0]
            a1=replace_first_gls(a, gls_offset, acronym_dict)
            if a1:
                a=a1
            else:
                return a
        else: # case of no s1 and s2:
            glspl_offset=s2.span()[0]
            a1=replace_first_glspl(a, glspl_offset, acronym_dict)
            if a1:
                a=a1
            else:
                return a
        s1=re.search('\\\\gls\{', a, re.IGNORECASE)
        s2=re.search('\\\\glspl\{', a, re.IGNORECASE)
    return a

# ligature. LaTeX commonly does it for ff, fi, fl, ffi, ffl, ...
ligrature_table= {'\ufb00': 'ff', # 'ï¬€'
                  '\ufb03': 'fâ€Œfâ€Œi', # 'ï¬ƒ'
                  '\ufb04': 'ffl', # 'ï¬„'
                  '\ufb01': 'fi', # 'ï¬'
                  '\ufb02': 'fl', # 'ï¬‚'
                  '\ua732': 'AA', # 'êœ²'
                  '\ua733': 'aa', # 'êœ³'
                  '\ua733': 'aa', # 'êœ³'
                  '\u00c6': 'AE', # 'Ã†'
                  '\u00e6': 'ae', # 'Ã¦'
                  '\uab31': 'aÉ™', # 'ê¬±'
                  '\ua734': 'AO', # 'êœ´'
                  '\ua735': 'ao', # 'êœµ'
                  '\ua736': 'AU', # 'êœ¶'
                  '\ua737': 'au', # 'êœ·'
                  '\ua738': 'AV', # 'êœ¸'
                  '\ua739': 'av', # 'êœ¹'
                  '\ua73a': 'AV', # 'êœº'  - note the bar
                  '\ua73b': 'av', # 'êœ»'  - note the bar
                  '\ua73c': 'AY', # 'êœ¼'
                  '\ua76a': 'ET', # 'êª'
                  '\ua76b': 'et', # 'ê«'
                  '\uab41': 'É™Ã¸', # 'ê­'
                  '\u01F6': 'Hv', # 'Ç¶'
                  '\u0195': 'hu', # 'Æ•'
                  '\u2114': 'lb', # 'â„”'
                  '\u1efa': 'IL', # 'á»º'
                  '\u0152': 'OE', # 'Å’'
                  '\u0153': 'oe', # 'Å“'
                  '\ua74e': 'OO', # 'ê'
                  '\ua74f': 'oo', # 'ê'
                  '\uab62': 'É”e', # 'ê­¢'
                  '\u1e9e': 'fs', # 'áº'
                  '\u00df': 'fz', # 'ÃŸ'
                  '\ufb06': 'st', # 'ï¬†'
                  '\ufb05': 'Å¿t', # 'ï¬…'  -- long ST
                  '\ua728': 'Tz', # 'êœ¨'
                  '\ua729': 'tz', # 'êœ©'
                  '\u1d6b': 'ue', # 'áµ«'
                  '\uab63': 'uo', # 'ê­£'
                  #'\u0057': 'UU', # 'W'
                  #'\u0077': 'uu', # 'w'
                  '\ua760': 'VY', # 'ê '
                  '\ua761': 'vy', # 'ê¡'
                  # 
                  '\u0238': 'db', # 'È¸'
                  '\u02a3': 'dz', # 'Ê£'
                  '\u1b66': 'dÊ', # 'ê­¦'
                  '\u02a5': 'dÊ‘', # 'Ê¥'
                  '\u02a4': 'dÊ’', # 'Ê¤'
                  '\u02a9': 'fÅ‹', # 'Ê©'
                  '\u02aa': 'ls', # 'Êª'
                  '\u02ab': 'lz', # 'Ê«'
                  '\u026e': 'lÊ’', # 'É®'
                  '\u0239': 'qp', # 'È¹'
                  '\u02a8': 'tÉ•', # 'Ê¨'
                  '\u02a6': 'ts', # 'Ê¦'
                  '\uab67': 'tÊ‚', # 'ê­§'
                  '\u02a7': 'tÊƒ', # 'Ê§'
                  '\uab50': 'ui', # 'ê­'
                  '\uab51': 'ui', # 'ê­‘' -- turned ui
                  '\u026f': 'uu', # 'É¯'
                  # digraphs with single code points
                  '\u01f1': 'DZ', # 'Ç±'
                  '\u01f2': 'Dz', # 'Ç²'
                  '\u01f3': 'dz', # 'Ç³'
                  '\u01c4': 'DÅ½', # 'Ç„'
                  '\u01c5': 'DÅ¾', # 'Ç…'
                  '\u01c6': 'dÅ¾', # 'Ç†'
                  '\u0132': 'IJ', # 'Ä²'
                  '\u0133': 'ij', # 'Ä³'
                  '\u01c7': 'LJ', # 'Ç‡'
                  '\u01c8': 'Lj', # 'Çˆ'
                  '\u01c9': 'lj', # 'Ç‰'
                  '\u01ca': 'NJ', # 'ÇŠ'
                  '\u01cb': 'Nj', # 'Ç‹'
                  '\u01cc': 'nj', # 'ÇŒ'
                  '\u1d7a': 'th', # 'áµº'
                  }

def replace_ligature(s):
    # check for ligratures and replace them with separate characters
    if not s:
        return s
    
    for l in ligrature_table:
        if s.find(l) >= 0:
            print("found ligrature {0} replacing with {1}".format(l, ligrature_table[l]))  
            s=s.replace(l, ligrature_table[l])
    #
    return s


def clean_and_transform_str(s):
    # remove preceeding and trailing white space
    s=s.strip()
    s=s.replace('\&', '&amp;')
    s=replace_ligature(s)
    return s
    

def main(argv):
    global Verbose_Flag
    global Use_local_time_for_output_flag
    global testing

    parser = optparse.OptionParser()

    parser.add_option('-v', '--verbose',
                      dest="verbose",
                      default=False,
                      action="store_true",
                      help="Print lots of output to stdout"
    )

    parser.add_option('-t', '--testing',
                      default=False,
                      action="store_true",
                      help="execute test code"
                      )

    parser.add_option('-j', '--json',
                      type=str,
                      default="fordiva.json",
                      help="JSON file for extracted data"
                      )

    parser.add_option('-a', '--acronyms',
                      type=str,
                      default="acronyms.tex",
                      help="acronyms file"
                      )

    options, remainder = parser.parse_args()

    Verbose_Flag=options.verbose
    if Verbose_Flag:
        print("ARGV      : {}".format(sys.argv[1:]))
        print("VERBOSE   : {}".format(options.verbose))
        print("REMAINING : {}".format(remainder))


    d=None                      # where the JSON data will be put

    pp = pprint.PrettyPrinter(indent=4, width=1024) # configure prettyprinter

    json_filename=options.json
    json_string=''
    if json_filename:
        try:
            with open(json_filename, 'r', encoding='utf-8') as json_FH:
                json_string=json_FH.read()
        except FileNotFoundError:
            print(f"File not found: {json_filename}")
            return 1

        try:
            d=json.loads(json_string)
            if Verbose_Flag:
                print(f"read JSON: {d}")

        except :
            print(f"Error in JSON in {json_filename}")
            return 1

    else:
        print(f"Unknown source for the JSON: {json_filename}")
        return 1

    # check for keywords
    keywords_dict=d.get('keywords', None)
    if keywords_dict and isinstance(keywords_dict, dict):
        for lang in keywords_dict:
            lang_keywords=keywords_dict.get(lang, None)
            keywords_str=lang_keywords.strip()
            keywords=keywords_str.split(',')
            cleaned_list = [clean_and_transform_str(keyword) for keyword in keywords]
    
            # Join the cleaned keywords back into a single string.
            d['keywords'][lang] = ', '.join(cleaned_list)

    #print("after cleaning keywords")
    #pp.pprint(d)
    
    # check for abstracts
    abstracts=d.get('abstracts', None)
    if abstracts:
        for lang in abstracts:
            abstracts[lang]=clean_up_abstract(abstracts[lang])

        any_acronyms_in_abstracts=False
        for lang in abstracts:
            acronyms_present=check_for_acronyms(abstracts[lang])
            if acronyms_present:
                any_acronyms_in_abstracts=True

        if any_acronyms_in_abstracts:
            acronyms_filename=options.acronyms
            print(f"Acronyms found, getting acronyms from {acronyms_filename}")
            acronym_dict=get_acronyms(acronyms_filename)
            if len(acronym_dict) == 0:
                print(f"no acronyms found in {acronyms_filename}")
            else:
                # entries of the form: acronym_dict[label]={'acronym': acronym, 'phrase': phrase}
                for lang in abstracts:
                    abstracts[lang]=spellout_acronyms_in_abstract(acronym_dict, abstracts[lang])

        if Verbose_Flag:
            for lang in abstracts:
                print(f"abstracts[{lang}]: {abstracts[lang]}")

    output_filename = json_filename[:-5] + "-HTML.json"
    if Verbose_Flag:
        print(f"output_filename={output_filename}")
    with open(output_filename, 'w', encoding='utf-8') as output_FH:
        j_as_string = json.dumps(d, ensure_ascii=False)
        print(j_as_string, file=output_FH)

if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))

